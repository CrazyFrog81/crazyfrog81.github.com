<!doctype html>
<html>
<head>
    <meta name="Robots" contect="none">
    <meta charset="UTF-8">

    <title>Zeng Wei's Homepage</title>
    <link rel="stylesheet" type="text/css" href="../zengwei.css" media="all"/>
    <script src="../info.js" type="text/javascript" defer></script>
</head>

<body>

<div class="content">
    <div id="info" class="id">
    </div>

    <div class="main pubs">
        <nav id="nav">
            <a href="..">HOME</a> &nbsp;&nbsp;
            <a href="../Research">RESEARCH</a> &nbsp;&nbsp;
            <a style="font-weight:bold">PUBLICATIONS</a> &nbsp;&nbsp;
            <a href="http://www.hkust-cival.com">TEAM</a> &nbsp;&nbsp;
            <a href="../vita">VITA</a> &nbsp;&nbsp;
            <!--            <a href="../blog">BLOG</a> &nbsp;&nbsp;-->
            <a href="../bookmark">BOOKMARK</a> &nbsp;&nbsp;
        </nav>

        <h3 style="margin:0 0 5px 0">All Publications (<a href="index.html">Referred List</a>)</h3>
        <text>* Corresponding author, <u>Students/RAs</u> under my supervision</text>
        <br>

        <h3 style="margin:20px 0 5px 0">Journals & Conferences</h3>

        <ol class="conference" style="font-size: 11px">
            <li>
                <u>Yilin Ye</u>, <u>Qian Zhu</u>, <u>Shishi Xiao</u>, Kang Zhang, <strong>Wei Zeng</strong>,
                "The Contemporary Art of Image Search: Iterative User Intent Expansion via Vision-Language Model",
                <b>Proceedings of The ACM SIGCHI Conference on Computer-Supported Cooperative Work & Social Computing (CSCW)</b>, 2024. Accepted.
            </li>
        </ol>

        <ol class="journal" style="font-size: 11px">
            <li num="32">
                <u>Shishi Xiao</u>*, <u>Qing Shi</u>*, <u>Lingdan Shao</u>, Bo Du, Yang Wang, Qiaomu Shen, <strong>Wei Zeng</strong>,
                "MetroBUX: A Topology-based Visual Analytics for Bus Operational Uncertainty EXploration",
                <b>IEEE Transactions on Intelligent Transportation Systems</b>, 2023. Accepted.
            </li>

            <li num="31">
                <u>Zezheng FENG</u>, Fang Zhu, Hongjun Wang, <u>Jianing Hao</u>, Shuang-Hua Yang, <strong>Wei Zeng</strong>, Huamin Qu,
                "HoLens: A Visual Analytics Design for Higher-order Movement Modeling and Visualization",
                <b>Computational Visual Media</b>, 2023. Accepted.
<!--                [<a href="">Paper</a>]-->
            </li>

            <li num="30">
                <u>Shishi Xiao</u>, Suizi Huang, Yue Lin, <u>Yilin Ye</u>, <strong>Wei Zeng*</strong>,
                "Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS 2023)</b>, 2024. Accepted.
                [<a href="https://arxiv.org/abs/2304.14630">Paper</a>]
            </li>

            <li>
                <u>Jianing Hao</u>, <u>Qing Shi</u> <u>Yilin Ye</u>, <strong>Wei Zeng*</strong>,
                "TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual
                Explanations",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS 2023)</b>, 2024. Accepted.
                [<a href="">Paper</a>]
            </li>
        </ol>

        <ol class="conference" style="font-size: 11px">
            <li num="100">
                <u>Liangwei Wang</u>, <u>Zhan Wang</u>, Xi Zhao and <strong>Wei Zeng*</strong>,
                “Storytelling in Frozen Frontier: Exploring Graphic-Based Approach for Creating Interactive Story Maps
                in Antarctica”,
                <b>Proc. 16th International Symposium on Visual Information Communication and Interaction (VINCI'23)</b>,
                Article No.: 2, Pages 1–8, 2023.
                [<a href="https://doi.org/10.1145/3615522.3615524" target="_blank" rel="noopener">DOI</a>] <b style="color: red">Best Paper</b>
            </li>

            <li style="margin-bottom: 7px">
                <u>Yihan Chen</u>, <u>Yilin Ye</u> and <strong>Wei Zeng*</strong>
                “The Rich, the Poor, and the Ugly: An Aesthetic-Perspective Assessment of NFT Values ”,
                <b>Proc. 16th International Symposium on Visual Information Communication and Interaction (VINCI'23)</b>,
                Article No.: 23, Pages 1–8, 2023.
                [<a href="https://doi.org/10.1145/3615522.3615545" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                <u>Yifan Cao</u>, Meng Xia, Kento Shigyo, Furui Cheng, Qianhang Yu, Xingxing Yang, Yang Wang, <strong>Wei
                Zeng*</strong> and Huamin Qu
                “NFTeller: Dual-centric Visual Analytics for Assessing Market Performance of NFT Collectibles”,
                <b>Proc. 16th International Symposium on Visual Information Communication and Interaction (VINCI'23)</b>,
                Article No.: 20, Pages 1–8, 2023.
                [<a href="https://doi.org/10.1145/3615522.3615578" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                <u>Jianing Hao</u>, Xibin Jiang, <u>Qing Shi</u> and <strong>Wei Zeng*</strong>,
                “Does Where You are Matter? A Visual Analytics System for COVID-19 Transmission Based on Social
                Hierarchical Perspective”,
                <b>Proc. 16th International Symposium on Visual Information Communication and Interaction (VINCI'23)</b>,
                Article No.: 6, Pages 1–5, 2023.
                [<a href="https://doi.org/10.1145/3615522.3615528" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                <u>Shihan Fu</u>, Liangliang Qiang and <strong>Wei Zeng*</strong>,
                “LOOP Meditation: Enhancing Novice's VR Meditation Experience with Physical Movement”,
                <b>Proc. 16th International Symposium on Visual Information Communication and Interaction (VINCI'23)</b>,
                Article No.: 16, Pages 1–5, 2023.
                [<a href="https://doi.org/10.1145/3615522.3615538" target="_blank" rel="noopener">DOI</a>]
            </li>
        </ol>

        <ol class="journal" style="font-size: 11px">
            <li>
                <u>Shishi Xiao</u>, <u>Yihan Hou</u>, Cheng Jin, <strong>Wei Zeng*</strong>,
                "WYTIWYR: A User Intent-Aware Framework with Multi-modal Inputs for Visualization Retrieval",
                <b>Computer Graphics Forum (Proc. EuroVis 2023)</b>, 42(3): 311-322, 2023.
                [<a href="https://arxiv.org/abs/2304.06991">Paper</a>]
            </li>

            <li>
                <em>Wei Zeng*</em>, <u>Xi Chen</u>, <u>Yihan Hou</u>, <u>Lingdan Shao</u>, <u>Zhe Chu</u>, Remco Chang,
                “Semi-Automatic Layout Adaptation for Responsive Multiple-View Visualization Design”,
                <b>IEEE Transactions on Visualization and Computer Graphics</b>, 2023. Accepted.
                [<a href="https://hkust-cival.com/projects/adaMV/">Homepage</a>]
                [<a href="https://hkust-cival.com/projects/adaMV/material/0_adapative_layout.pdf">Paper</a>]
                [<a href="https://doi.org/10.1109/TVCG.2023.3240356" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li>
                <u>Yilin Ye</u>, <u>Rong Huang</u>, <em>Wei Zeng*</em>,
                “VISAtlas: An Image-based Exploration and Query System for Large Visualization Collections via Neural
                Image Embedding”,
                <b>IEEE Transactions on Visualization and Computer Graphics</b>, 2023. Accepted.
                [<a href="https://hkust-cival.com/projects/visatlas/">Homepage</a>]
                [<a href="https://hkust-cival.com/projects/visatlas/material/vis_atlas.pdf">Paper</a>]
                [<a href="https://doi.org/10.1109/TVCG.2022.3229023" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li>
                <u>Zhen Wen</u>, <em>Wei Zeng*</em>, Luoxuan Weng, Yihan Liu, Mingliang Xu, Wei Chen*,
                “Effects of View Layout on Situated Analytics for Multiple Representations in Immersive Visualization”,
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VIS 2022)</b>, 29(1): 440 - 450,
                2023.
                [<a href="https://hkustgz-my.sharepoint.com/:b:/g/personal/weizeng_hkust-gz_edu_cn/EVwKqTKNaPVGkkP5qunovLkBV85lLlAQhH9284l4-cfxzQ?e=PhTyfg">Paper</a>]
                [<a href="https://doi.org/10.1109/TVCG.2022.3209475" target="_blank" rel="noopener">DOI</a>]
            </li>

            <li>
                Jincheng Jiang, Wei Tu, Hui Kong, <em>Wei Zeng</em>, Rui Zhang, Milan Konecny,
                “Large-scale urban multiple-modal transport evacuation for mass gathering events considering pedestrian
                and public transit system”,
                <b>IEEE Transactions on Intelligent Transportation System</b>, 23(12):23059–23069, 2022.
                [<a href="https://ieeexplore.ieee.org/document/9901464"
                    target="_blank" rel="noopener">DOI</a>]
            </li>

            <li>
                Shihui Guo, Yubin Shi, Pintong Xiao, Yinan Fu, Juncong Lin, <em>Wei Zeng</em>, Tong-Yee Lee,
                “Creative and Progressive Interior Color Design with Eye-tracked User Preference”,
                <b>ACM Transactions on Computer-Human Interaction</b>, 30(1), Article 5, 31 pages, 2022. [<a
                    href="https://hkustgz-my.sharepoint.com/:b:/g/personal/weizeng_hkust-gz_edu_cn/Ecbmec31RPNJlUGqnQyu4wkBMGGwjeO8qebPc9Nnl4TbsQ?e=Zrxj1T"
                    target="_blank" rel="noopener">Paper</a>] [<a href="https://dl.acm.org/doi/10.1145/3542922"
                                                                  target="_blank" rel="noopener">DOI</a>]
            </li>
            <li>
                <u>Yanna Lin</u>, <em>Wei Zeng*</em>, Yu Ye, Huamin Qu, “Saliency-aware color harmony models for outdoor
                signboard”, <span style="font-weight: bold;">Computers &amp; Graphics</span>, 105: 25 - 25, 2022.  [<a
                    href="https://hkustgz-my.sharepoint.com/:b:/g/personal/weizeng_hkust-gz_edu_cn/ERlV2a1DjMxNkuGnXqA6NwkBJzwWNR1P81vtnFOM7bkevw?e=Kfk3Ic"
                    target="_blank" rel="noopener">Paper</a>][<a href="https://doi.org/10.1016/j.cag.2022.04.012"
                                                                 target="_blank" rel="noopener">DOI</a>]
            </li>
            <li>
                <u>Shidong Wang</u>, <em>Wei Zeng*</em>, <u>Xi Chen</u>, Yu Ye, Yu Qiao, Chi-Wing Fu, “ActFloor-GAN:
                Activity-Guided Adversarial Networks for Human-Centric Floorplan Design”,
                <b>IEEE Transactions on Visualization and Computer Graphics</b>, 29(3): 1610-1624, 2023.
                [<a href="https://arxiv.org/abs/2111.03545">Paper</a>]
                [<a href="https://github.com/yuanlinping/deep_colormap_extraction">Code</a>]
            </li>

            <li>
                <em>Wei Zeng</em>, <u>Chengqiao Lin</u>, Kang Liu, Juncong Lin*, Anthony K. H. Tung, "Modeling Spatial
                Nonstationarity via Deformable Convolutions for Deep Traffic Flow Prediction", <b>IEEE Transactions on
                Knowledge and Data Engineering</b>, 35(3): 2796 - 2808, 2023.
                [<a href="https://arxiv.org/abs/2101.12010">Paper</a>] [<a
                    href="https://doi.org/10.1109/TKDE.2021.3112977">DOI</a>]
            </li>

            <li>
                <u>Chi Zhang</u>, <em>Wei Zeng*</em>, Ligang Liu, "UrbanVR: An immersive analytics system for
                context-aware urban design", <b>Computers & Graphics</b>, 99: 128-138, 2021.
                [<a href="https://arxiv.org/abs/2107.00227">Paper</a>] [<a href="https://youtu.be/GIq8U7o9_fQ">Video</a>]
            </li>

            <li>
                <u>Mengyang Wu</u>, <em>Wei Zeng*</em>, Chi-Wing Fu*, "FloorLevel-Net: Recognizing Floor-Level Lines
                with Height-Attention-Guided Multi-task Learning",
                <b>IEEE Transactions on Image Processing</b>, 30: 6686-6699, 2021.
                [<a href="https://wumengyangok.github.io/Project/FloorLevelNet">Github</a>] [<a
                    href="https://arxiv.org/abs/2107.02462">Paper</a>]
            </li>

            <li>
                <u>Lingdan Shao</u>, <u>Zhe Chu</u>, <u>Xi Chen</u>, <u>Yanna Lin</u>, <em>Wei Zeng*</em>, "Modeling
                Layout Design for Multiple-View Visualization via Bayesian Inference",
                <b>Journal of Visualization (Proc. ChinaVis 2021 <span
                        style="color: red">Best Paper Honorable Mention</span>)</b>, 24(6): 1237-1252,
                2021. [<a href="papers/2021%20bayes_mv_layout.pdf">Paper</a>]
            </li>

            <li>
                <u>Lin-Ping Yuan</u>, <em>Wei Zeng*</em>, Siwei Fu, Zhiliang Zeng, Haotian Li, Chi-Wing Fu, Huamin Qu,
                “Deep Colormap Extraction from Visualizations”,
                <b>IEEE Transactions on Visualization and Computer Graphics</b>, 28(12): 4048 - 4060, 2022.
                [<a href="https://github.com/yuanlinping/deep_colormap_extraction">Github</a>]
                [<a href="https://arxiv.org/abs/2103.00741">Paper</a>]
            </li>

            <li>
                <u>Xi Chen</u>, <em>Wei Zeng*</em>, <u>Yanna Lin</u>, Hayder Mahdi Al-maneea, Jonathan C Roberts, Remco
                Chang, "Composition and Configuration Patterns in Multiple-View Visualizations",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE InfoVis 2020)</b>, 27(2):
                1514-1524, 2021.
                [<a href="https://mvlandscape.bitbucket.io/">Homepage</a>]
                [<a href="https://arxiv.org/abs/2007.15407">Paper</a>]
                [<a href="https://youtu.be/WSPCbIdDnFQ">Video</a>]
                [<a href="https://valt.cs.tufts.edu/papers/multiple-view/mv_data.zip">Data</a>]
            </li>

            <li>
                <em>Wei Zeng</em>, <u>Chengqiao Lin</u>, Juncong Lin*, Jincheng Jiang, Jiazhi Xia, Cagatay Turkay, Wei
                Chen,
                "Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VAST 2020)</b>, 27(2): 839-848,
                2021.
                [<a href="https://arxiv.org/abs/2007.15486">Paper</a>][<a href="https://youtu.be/FC7dRXbrZ4s">Video</a>]
            </li>

            <li>
                <u>Zezheng Feng</u>, <u>Haotian Li</u>, <em>Wei Zeng*</em>, Shuang-Hua Yang, Huamin Qu,
                "Topology Density Map for Urban Data Visualization and Analysis",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VAST 2020)</b>, 27(2): 828-838,
                2021.
                [<a href="https://arxiv.org/abs/2007.15828">Paper</a>]
                </td>
                </tr>
            </li>

            <li>
                Jiacheng Pan, Wei Chen, Xiaodong Zhao, Shuyue Zhou, <em>Wei Zeng</em>, Minfeng Zhu, Jian Chen, Siwei Fu,
                Yingcai Wu,
                "Exemplar-based Layout Fine-tuning for Node-link Diagrams",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE InfoVis 2020)</b>, 27(2):
                1655-1665, 2021.
                [<a href="https://arxiv.org/abs/2008.00666">Paper</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng*</em>, <u>Ao Dong</u>, <u>Xi Chen</u>, Zhanglin Cheng,
                "VIStory: Interactive Storyboard for Exploring Visual Information in Scientific Publications",
                <b>Journal of Visualization</b> (extended version of VINCI 2019 Best Paper), 24(1): 69-84,
                2021.
                [<a href="http://link.springer.com/article/10.1007/s12650-020-00688-1">Paper</a>]
                [<a href="https://dongoa.github.io/projects/VIStory/index.html">Homepage</a>]
                [<a href="https://dongoa.github.io/VIStory/">Interface</a>]
                [<a href="https://youtu.be/lSCuySOEoM8">Video</a>]
            </li>

            <li style="margin-bottom: 7px">
                <u>Zhiliang Zeng</u>, <u>Mengyang Wu</u>, <em>Wei Zeng*</em>, and Chi-Wing Fu,
                "Deep Recognition of Vanishing-Point-Constrained Building Planes in Urban Street Views",
                <b>IEEE Transactions on Image Processing</b>, 29: 5912-5923, 2020.
                [<a href="papers/2020%20ARScape.pdf">Paper</a>]
                [<a href="https://doi.org/10.1109/TIP.2020.2986894">DOI</a>]
            </li>
        </ol>

        <ol class="conference" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                Zengyang Gong, Bo Du, Zhidan Liu, <em>Wei Zeng</em>, Pascal Perez, Kaishun Wu,
                “SD-seq2seq: A Deep Learning Model for Bus Bunching Prediction Based on Smart Card Data”,
                <b>Proc. ICCCN 2020</b>, pp. 1 - 9, 2020.
            </li>

            <li style="margin-bottom: 7px">
                Qiaomu Shen, Yanhong Wu, Yuzhe Jiang, <em>Wei Zeng</em>, Alexis K. H. LAU, Anna Vianova, and Huamin Qu,
                "Visual Interpretation of Recurrent Neural Network on Multi-dimensional Time-series Forecast",
                <b>Proc. IEEE PacificVis 2020</b>, pp. 61-70, 2020.
                [<a href="papers/2020%20AirRNNVis.pdf">Paper</a>]
                [<a href="https://youtu.be/IOA5_uAvohQ">Video</a>]
            </li>
        </ol>

        <ol class="journal" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                <u>Zhutian Chen</u>, <em>Wei Zeng*</em>, <u>Zhiguang Yang</u>, Lingyun Yu, Chi-Wing Fu, and Huamin Qu,
                "LassoNet: Deep Lasso-Selection of 3D Point Clouds",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE SciVis 2019)</b>,
                26(1): 195-204, 2020.
                [<a href="https://arxiv.org/pdf/1907.13538.pdf">Paper</a>]
                [<a href="https://lassonet.github.io/">Homepage</a>]
                [<a href="https://youtu.be/OsE_LmR-Ec4">Video</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, <u>Qiaomu Shen</u>, <u>Yuzhe Jiang</u>, Alex Telea,
                "Route-Aware Edge Bundling for Visualizing Origin-Destination Trails in Urban Traffic",
                <b>Computer Graphics Forum (Proc. EuroVis 2019)</b>,
                38(3): 581-593, 2019.
                [<a href="papers/2019_RAEB.pdf">Paper</a>]
                [<a href="../presentation/EuroVis19_ppt.pdf">Presentation</a>]
                [<a href="https://doi.org/10.1111/cgf.13712 ">DOI</a>]
                [<a href="https://youtu.be/SHZmj4p1WwQ">Video</a>]
            </li>

            <li style="margin-bottom: 7px">
                Yu Ye, <em>Wei Zeng*</em>, Qiaomu Shen, Xiaohu Zhang, Yi Lu,
                "The visual quality of streets: A human-centred continuous measurement based on machine learning
                algorithms and street view images",
                <b>Environment and Planning B: Urban Analytics and City Science</b>,
                46(8): 1439-1457, 2019.
                [<a href="https://sci-hub.tw/10.1177/2399808319828734">Paper</a>]
                [<a href="https://doi.org/10.1177/2399808319828734">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                Yu Ye, Daniel Richards, Yi Lu, Xiaoping Song, Yu Zhuang, <em>Wei Zeng</em>, Teng Zhong,
                "Measuring daily accessed street greenery: A human-scale approach for informing better urban planning
                practices",
                <b>Landscape and Urban Planning</b>, 191: 103434, 2019.
                [<a href="papers/2018%20Measuring%20daily%20accessed%20street%20greenery.pdf">Paper</a>]
                [<a href="https://www.sciencedirect.com/science/article/pii/S0169204618309940?via%3Dihub">DOI</a>]
            </li>
        </ol>
        <ol class="conference" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                <u>Ao Dong</u>, <em>Wei Zeng*</em>, <u>Xi Chen</u>, Zhanglin Cheng,
                "VIStory: Interactive Storyboard for Exploring Visual Information in Scientific Publications",
                <b>Proc. International Symposium on Visual Information Communication and Interaction (VINCI) </b>,
                12:1-8, 2019. <b style="color: red">Best Paper</b>
                [<a href="papers/2019 VIStory.pdf">Paper</a>]
                [<a href="https://dongoa.github.io/projects/VIStory/index.html">Homepage</a>]
                [<a href="https://dongoa.github.io/VIStory/">Interface</a>]
                [<a href="https://youtu.be/lSCuySOEoM8">Video</a>]
            </li>
        </ol>


        <ol class="journal" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Yu Ye,
                "VitalVizor: A Visual Analytics System for Studying Urban Vitality",
                <b>IEEE Computer Graphics and Applications (Special Issue on Visualization for Smart City
                    Application)</b>
                38(5): 38-53, 2018.
                [<a href="papers/2018%20VitalVizor.pdf">Paper</a>]
                [<a href="https://ieeexplore.ieee.org/document/8474512">DOI</a>]
                [<a href="https://www.youtube.com/watch?v=MAxNu6jc2mo">Video</a>]
                [<a href="http://v.youku.com/v_show/id_XMzg5ODc4MjczNg====.html">Youku</a>]
            </li>

            <li style="margin-bottom: 7px">
                <u>Qiaomu Shen</u>, <em>Wei Zeng*</em>, Yu Ye, Stefan Müller Arisona, Simon Schubiger, Remo Burkhard and
                Huamin Qu,
                "StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE SciVis'17)</b>,
                24(1): 1004 - 1013, 2018.
                [<a href="papers/2018%20streetvizor.pdf">Paper</a>]
                [<a href="https://ieeexplore.ieee.org/document/8017655">DOI</a>]
                [<a href="https://www.youtube.com/watch?v=K-bCY71P8MM&list=PL3-tIMzrYMbKRmrau4n1HIbMJMzSma8wh&index=8&t=47s">Video</a>]
                [<a href="http://v.youku.com/v_show/id_XMzg5ODc4MjczNg====.html">Youku</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, Simon Schubiger, Remo Burkhard and Kwan-Liu Ma,
                "A Visual Analytics Design for Studying Rhythm Patterns from Human Daily Movement Data",
                <b>Visual Informatics</b> (an extended version of SIGGRAPH Asia Symp. Vis. 2016 paper),
                1(2): 81-91, 2017.
                [<a href="papers/2017%20Movement%20Rhythm.pdf">Paper</a>]
                [<a href="https://www.sciencedirect.com/science/article/pii/S2468502X17300256?via%3Dihub">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, Simon Schubiger, Remo Burkhard, and Kwan-Liu Ma,
                "Visualizing the Relationship between Human Mobility and Points-of-Interest",
                <b>IEEE Transactions on Intelligent Transportation Systems (Special Issue on Visual Analysis for
                    ITS)</b>,
                18(8): 2271-2284, 2017.
                [<a href="papers/2017%20POI.pdf">Paper</a>]
                [<a href="http://ieeexplore.ieee.org/document/7817741/">DOI</a>]
                [<a href="https://youtu.be/aaBU9xJpOj0">Video</a>]
                [<a href="http://v.youku.com/v_show/id_XMzg5ODc3MjIxMg====.html">Youku</a>]
            </li>
        </ol>
        <ol class="conference" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                Jan Perhac, <em>Wei Zeng*</em>, Shiho Asada, Remo Burkhard, Stefan Mueller Arisona, Simon Schubiger,
                Berhard Klein,
                "Urban Fusion: Visualizing urban data fused with social feeds via a game engine",
                <b>Proc. International Conference on Information Visualisation</b>,
                pp. 312-317, 2017. <b style="color:red">Best Paper</b>
                [<a href="papers/2017%20Urban%20Fusion.pdf">Paper</a>]
            </li>

            <li style="margin-bottom: 7px">
                Aurel von Richthofen, <em>Wei Zeng*</em>, Shiho Asada, Remo Burkhard, Felix Heisel, Stefan Mueller
                Arisona, Simon Schubiger,
                "Urban Mining: Visualizing the Availability of Construction Materials for Re-use in Future Cities",
                <b>Proc. International Conference on Information Visualisation</b>,
                pp. 306-311, 2017.
                [<a href="papers/2017%20Urban%20Mining.pdf">Paper</a>]
            </li>
        </ol>
        <ol class="journal" style="font-size: 11px">

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, Alexander Erath, Huamin Qu,
                "Visualizing Waypoints-Constrained Origin-Destination Patterns for Massive Transportation Data",
                <b>Computer Graphics Forum</b>,
                35(8): 95-107, 2016.
                [<a href="papers/2016%20Waypoints%20OD.pdf" rel="noopener">Paper</a>]
                [<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/cgf.12778">DOI</a>]
                [<a href="https://www.youtube.com/watch?v=lAdqxSURCGQ" target="_blank"
                    rel="noopener noreferrer">Video</a>]
            </li>
        </ol>

        <ol class="conference" style="font-size: 11px">
            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, Simon Schubiger, Remo Burkhard and Kwan-Liu Ma,
                "A visual Analytics Design for Studying Crowd Movement Rhythms for Public Transportation Data",
                <b>Proc. SIGGRAPH Asia Symposium on Visualization</b>,
                pp. 4:1-4:7, 2016.
                [<a href="papers/2016%20rhythm_vis.pdf.pdf">Paper</a>]
                [<a href="https://dl.acm.org/citation.cfm?id=3002152">DOI</a>]
                [<a href="https://www.youtube.com/watch?v=GsWnCrgHVqs">Video</a>]
            </li>
        </ol>

        <ol class="journal" style="font-size: 11px">
            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, Alexander Erath, Huamin Qu,
                "Visualizing Mobility of Public Transportation System",
                <b>IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VAST'14)</b>,
                20(12): 1833-1842, 2014.
                [<a href="papers/2014%20Mobility.pdf" rel="noopener">Paper</a>]
                [<a href="http://ieeexplore.ieee.org/document/6876029/">DOI</a>]
                [<a href="http://youtube=http://www.youtube.com/watch?v=Q95c8PpneT8">Video</a>]
                [<a href="http://v.youku.com/v_show/id_XMzg5ODc1NDI2NA====.html">Youku</a>]
            </li>

            <li style="margin-bottom: 7px">
                Afian Anwar,<em>Wei Zeng</em>, Stefan Müller Arisona,
                "The Time Space Diagram Revisited",
                <b>Transportation Research Record: Journal of the Transportation Research Board (Proc. TRB'14)</b>
                No. 14-1046, 2014.
                [<a href="papers/2014%20The%20Time%20Space%20Diagram%20Revisited.pdf" rel="noopener">Paper</a>]
                [<a href="https://trid.trb.org/view/1287611">DOI</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Xianfeng Huang, Stefan Müller Arisona and Ian Vince McLoughlin,
                "Classifying Watermelon Ripeness by Analysing Acoustic Signals Using Mobile Devices",
                <b>Personal and Ubiquitous Computing</b>,
                18(7): 1753-1762, 2014.
                [<a href="papers/2013%20watermelon.pdf" rel="noopener">Paper</a>]
                [<a href="https://link.springer.com/article/10.1007%2Fs00779-013-0706-7">DOI</a>]
                [<a href="https://gohkust-my.sharepoint.com/:u:/g/personal/weizeng_ust_hk/EQVP86Q9deJHg4g9Vf33JoIBXs2KIaARheGd2eTRCshrww?e=WomARc">Data</a>]
            </li>

            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chi-Wing Fu, Stefan Müller Arisona, and Huamin Qu,
                "Visualizing Interchange Patterns in Massive Movement Data",
                <b>Computer Graphics Forum (Proc. EuroVis'13)</b>,
                32(3pt3): 271-280, 2013.
                [<a href="papers/2013%20interchange.pdf" rel="noopener">Paper</a>]
                [<a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.12114">DOI</a>]
                [<a href="http://www.youtube.com/watch?v=_QWnA1k2ZrU" rel="noopener">Video</a>]
                [<a href="http://v.youku.com/v_show/id_XMzg5ODc1MjU1Mg====.html">Youku</a>]
            </li>

            <li style="margin-bottom: 7px">
                Ian Vince McLoughlin, I Komang Narendra, Leong Hai Koh, Quang Huy Nguyen, Bharath Seshadri, <em>Wei
                Zeng</em>, Chang Yao,
                "Campus Mobility for the Future: The Electric Bicycle",
                <b>Digital Urban Modeling and Simulation</b>,
                2(1): 1-12, 2012.
                [<a href="papers/2012%20Campus%20Mobility%20for%20the%20Future-The%20Electric%20Bicycle.pdf"
                    rel="noopener">Paper</a>]
                [<a href="http://www.oalib.com/paper/8928#.WsZGFdNuZTY">DOI</a>]
            </li>
        </ol>

        <ol class="conference" style="font-size: 11px">
            <li style="margin-bottom: 7px">
                <em>Wei Zeng</em>, Chen Zhong, Afian Anwar, Stefan Müller Arisona, and Ian Vince McLoughlin,
                "MetroBuzz: Interactive 3D Visualization of Spatiotemporal Data",
                <b>Proc. International Conference on Computer & Information Science</b>,
                vol. 1, pp. 143-147, 2012.
                [<a href="papers/2012%20Metrobuzz.pdf" rel="noopener">Paper</a>]
                [<a href="http://ieeexplore.ieee.org/document/6297228/" rel="noopener">DOI</a>]
                [<a href="https://www.youtube.com/watch?v=zesDn93MNpo">Video</a>]
            </li>
        </ol>

        <h3 style="margin:20px 0 5px 0">Book Chapters</h3>

        <ol class="bc" style="font-size: 11px">
            <li>
                <em>Wei Zeng</em>, Jan Perhac, Shiho Asada, Simon Schubiger, Stefan Mueller Arisona, and Remo Burkhard,
                "Singapore Views: A Collaborative Interactive Visualisation and Analysis Framework for Urban Planning
                and Design",
                <b>FCL Indicia II</b>, Lars Müller Publishers, 2018.
                [<a href="papers/2018%20Singapore%20Views.pdf" rel="noopener">Paper</a>]
            </li>

            <li>
                Simon Schubiger, Stefan Mueller Arisona, Chen Zhong, <em>Wei Zeng</em>, and Remo Burkhard,
                "Advanced Tools and Workflows for Urban Designers",
                <b>FCL Indicia II</b>, Lars Müller Publishers, 2018.
                [<a href="papers/2018%20Singapore%20Views.pdf" rel="noopener">Paper</a>]
            </li>

            <li>
                Chen Zhong, Tao Wang, <em>Wei Zeng</em>, and Stefan Müler Arisona,
                "Spatiotemporal Visualization: A Survey and Outlook",
                <b>Digital Urban Modeling and Simulation</b>, vol. 242, pp. 299-317, 2012.
                [<a href="papers/2012%20Spatiotemporal%20Visualisation%20A%20Survey%20and%20Outlook.pdf" rel="noopener">Paper</a>]
                [<a href="https://link.springer.com/chapter/10.1007%2F978-3-642-29758-8_16">DOI</a>]
            </li>
        </ol>

        <h3 style="margin:20px 0 5px 0">Thesis</h3>
        <p style="font-size: 11px; padding-left: 10px">
            <em>Wei Zeng</em>, "Visual Analytics for Massive Urban Public Transport Data", <em>School of Computer
            Engineering, Nanyang Technological University</em>, 2015.
            [<a href="papers/2015%20Thesis_ZengWei.pdf" rel="noopener">Thesis</a>]
        </p>
    </div>
</div>

</body>
</html>
