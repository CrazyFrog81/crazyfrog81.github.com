%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Collection}
\label{sec:data}

% To investigate design patterns of existing multiple view interfaces, we first \emph{image selection} (Sec.~\ref{ssec:mv_collection}), then \emph{image annotation} (Sec.~\ref{ssec:label_tool}).

To investigate design patterns of existing multiple view interfaces, the first significant thing is to collect data so that we can conduct data-driven analysis. 
In this section, we extract good practices from some representative visualization conferences in IMAGE form using automatic figure extraction method and filter out those mismatching work scope (Sec.~\ref{ssec:mv_collection}). Then we develop a label tool to label these collected images and store labeled results as data in JASON syntax(Sec.~\ref{ssec:label_tool}) manually.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Image Selection}
\label{ssec:mv_collection}


Our experimental data are selected from publications in representative visualization conferences (i.e., IEEE VIS, EuroVis and IEEE PacificVis in 2011 - 2019), since we consider that the multiple view interfaces in these conference papers are well designed and influential.
% Our experimental data are selected from figures in publications from representative visualization conferences (i.e., IEEE VIS, EuroVis and IEEE PacificVis in 2011 - 2019), since we consider that the multiple view interfaces in these conference papers are well designed and influential.
Thus, we firstly crawled a total of 1,976 papers, including 1,149 from IEEE VIS, 475 from EuroVis and 352 from IEEE PacificVis. 

In order to extract figures from papers, we used an automatic method of figure extraction. 
We first employed \textit{PyMuPDF} 
% $\footnote{A python libraryï¼šhttps:\/\/pypi.org\/project\/PyMuPDF\/1.10.0\/}$ 
and \textit{PDFtohtml} 
% $\footnote{A utility: https:\/\/sourceforge.net\/projects\/pdftohtml\/ }$ 
to convert papers in \textit{PDF} form to \textit{JPG} and \textit{XML} forms, respectively. 
Then according to the location of the keywords \emph{Fig.} or \emph{Figure} in the \textit{XML} file, we can locate the position of all figures of one paper. 
Lastly, these figures were extracted from the \textit{JPG} file based on their position.


In this work, we aim for exploring the underlying patterns of multiple views design. 
Therefore, we need to select interfaces with multiple view visualization from extracted figures.

% Based on work scope (Sec.~\ref{ssec:scope}), we mainly focus on the interface consisting of two or more views, filtering out one-view interface.
% \yn{ and also those interface are not system?}
% The filtering process is listed:
% =======
Based on work scope (Sec.~\ref{ssec:scope}), we mainly focus on the interface consisting of two or more views, filtering out which are one-view interfaces or are not a system.
The filtering process is:
% \begin{itemize}
%   \item
  Firstly, we remove figures with just one view;
  % without multiple views.
  % \item
  Secondly, we identify whether resulting figures have multiple view visualization or just display some image together by querying its description in the corresponding paper;
  % \item
  Finally, if there are more than one multiple system interface in a paper, we select the representative one.
% \end{itemize}

Based on this filtering process, we manually selected 360 images of multiple view interfaces from an initial collection of 16,891 figures.
Table.~\ref{tab:conf-num} presents our final result of collected multiple view interfaces.


% \begin{table}[H]
% \caption{Number of MV interfaces in IEEE VIS, EuroVis, IEEE PacificVis in 2011 - 2019}
% \scriptsize
% \renewcommand\tabcolsep{3.0pt}
% \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c}
% \hline
%    Venue & '11 & '12 & '13 & '14 & '15
%   & '16 & '17 & '18 & '19 & Total\\ 
% \hline
% VAST & 18 & 13 & 19 & 34 & 25& 21 & 25 & 26 & 17& 198 \\ 
% InfoVis & 4 & 7 & 4 & 7 & 7 & 4 & 4 & 5 & 6& 48 \\ 
% SciVis & 0 & 2 & 2 & 3 & 7 & 3 & 4 & 3 & 3& 27 \\ 
% EuroVis & 7 & 5 & 2 & 3 & 1 & 6 & 5 & 4 & 14& 47\\ 
% PacificVis & 3 & 1 & 2 & 3 & 3 & 6 & 5 & 7 & 10 & 40 \\ 
% \hline
% \end{tabular}
% \label{tab:conf-num}
% \end{table}
\begin{table}[H]
\caption{Number of MV interfaces in IEEE VIS (VAST, InfoVis, SciVis), EuroVis, PacificVis in 2011 - 2019}
% \renewcommand\tabcolsep{3.0pt}
\begin{tabular}{c}
\begin{minipage}{0.1\textwidth}
\includegraphics[width=85mm,height=18mm]{figures/fig3_stats/table.pdf}
\end{minipage}
\end{tabular}
\label{tab:conf-num}
\end{table}

As shown in this table, the number of MV interfaces in IEEE VIS far outweighs the figure for IEEE PacificVis and EuroVis, since papers in VAST (i.e., one of IEEE VIS conference) focus on using visual interaction techniques to support data analysis. 
And the another reason is that this similar trend was seen in the original data.
IEEE VIS included more MV interfaces in 2014 and 2015 than other years and it saw a sharp decrease in 2019 while EuroVis and PacificVis had the maximum papers in 2019.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Image Annotation}
\label{ssec:label_tool}


\begin{figure}[t]
  \centering
  % \vspace*{-1mm}
% <<<<<<< HEAD
%   \includegraphics[width=0.9\textwidth]{figures/fig2_label/label.pdf} \\
% =======
  \includegraphics[width=0.495\textwidth]{figures/fig2_label/label.pdf}
% >>>>>>> 36d78eb6d4b6e10497c760c3c72c7695af0c8b27
  % \vspace*{-4mm}
  \caption{\cx{Interface for labeling multiple views in visualization}.}
  \label{fig:vis_process}
  \vspace*{-3mm}
\end{figure}

To explore deeply multiple view designs and further analyze the composition and configuration of multiple view interface,
we develop a label tool (shown in Fig.\ref{fig:vis_process}) to label the view attributes manually.
Before describing the details of the label tool, we list the labeling rules firstly.
As mentioned on Sec.~\ref{ssec:spec}, we code the interface as {\color{red}xxx}. Our label rules are consistent with this ... 
We first label small multiples and views that we can name, which form \textit{level 1}. 
And for the small multiples in \textit{level 1}, we label views in small multiples as \textit{level 2}. 
Specifically, the panel defined on Sec.~\ref{ssec:spec} has three more rules when labeling:
(a)
We merge adjacent panels with same width or same height as one panel; 
We annotate some panels as one panel since they are arranged together; 
% We notice that many panels are arranged together, in which cases we annotate them as one panel.
(b)
If the panel controls interface globally whose height or width is below a tenth of the corresponding total length, we ignore it; 
% If the panel is around the interface and its height or width is below a tenth of the corresponding total length, we ignore it; 
(c)
If the panel controls interface locally, we merge it into the closest view.
% If the panel is not at the boundary of the interface, we merge it into the closest view.
% We need to further analyze the composition and configuration of multiple view interface, so that we can be sufficient for exploring multiple view design. 
% Therefore, we develop a label tool (Fig.\ref{fig:vis_process} left) to fulfill the requirement.
% For each system interface figure, we manually labeled the view attributes using a label tool.
While for the label tool, it consists of three view components: \textit{Display View, Control View} and \textit{History View}. 

\begin{itemize}
\item
\textbf{Display View} is the space displaying the currently selected multiple views interface.
Users can segment the selected interface directly by drawing rectangles based on label rules mentioned above.
% on Sec.~\ref{ssec:spec}. 
% \yn{the labeling rules need to be completed}

\item
\textbf{Control View} consists of 2 parts, the one in blue background and the one in gray.
In the blue background, there are four buttons representing \textit{the previous one, the next one, save and load} respectively.
Specifically, \textit{load} button is to load the labeled result about the corresponding figures and enable user to modify.
While after user drawing a rectangle to split a view in \textit{Display View}, the \emph{Control View} in the gray background provides blanks consisting of \emph{View ID}, \emph{Hierarchy} and \emph{Type} with same color bar on the left accordingly.
Therefore, users can record related information about corresponding views in the blanks.
% And there are four buttons at the top of the \emph{Control View} to jump to the previous image, jump to the next image, save the image, and re-load the labeled data respectively.
% Especially, the re-load button enables users to load the labeled data and modify the data.

\item 
\textbf{History View} is made up of figure thumbnail to facilitate users to label figures.
The labeled ones are in the gray background while the unlabeled are in the white background.
Thus, users can know which figures are marked and which are not and select unlabeled figure to label.

\end{itemize}

In order to make manually marked corpus more meaningful and influential, we label each MV interfaces following the label rules strictly.
 % according to statement of the views in Sec.~\ref{ssec:spec}.
% \yn{no mentioned the labeling rules}
First, we draw a red rectangle to identify the main interface of the selected image in \textit{display view}, ignoring the switch window and the pop-up window.
Then according to the definition of \textit{view type} (Sec.\ref{ssec:spec}), this selected image is segmented with rectangles of different colors and the corresponding properties are input into the \textit{control view}. 
% When judging a view as small multiples, only one view needs to be marked in the corresponding level 2. 
% \yn{need to updated}
Finally, we store our processed data in JSON format. 
In this JSON data, we record the width and height of the interface and an array named \textit{views} storing all views. 
Therefore, the size of this array means the number of the views and small multiples of this interface and one element of this array is one node of \textit{level 1}.
Every element of the array \textit{views} includes \textit{hierarchy}, the figures of \textit{bbox} (i.e., x,y,w,h), \textit{view type} and an array named \textit{mid view}.
Specifically, the null \textit{mid view} means that the \textit{view type} is not small multiples, while the non-null \textit{mid view} stores the small views in corresponding small multiples forming \textit{level 2}. 
The element of \textit{mid view} has almost the same structure as \textit{views} but without the array \textit{mid view}.
One more to mentioned, if there is any doubt about the labeled data, our group will discuss it to make a agreement and reload the original data to modify.

 % \emph{e.g.,} one showed in the right of Fig.\ref{fig:vis_process}.
% \yn{here, need to add description about the labeled result. like, the array \textit{views} stored the views. }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Alignment}
\label{ssec:alignment}
In the image annotation mentioned above, manual labeling may cause errors in the bounding box of views, e.g., the gaps or overlaps between the boundaries of views.
To reduce these errors, we need to align views. 
Initially, all views in \textit{level 1} of the interface are stored in the set to be aligned as $A= \{v_{i}\}_{i=1}^n$, where $n$ indicate the number of views in \textit{level 1}.
% need to be aligned in aligned set $A$.
And based on JSON data in Sec.~\ref{ssec:label_tool}, here we employ \textit{hierarchy} and \textit{bbox} to represent $v$, i.e.,$(x, y, h, w, hierarchy)$.

We develop a simple yet effective alignment algorithm to align views.
The algorithm works as follows:

\begin{algorithm}[H]
\caption{Alignment}
\begin{algorithmic}[1]
\While{$A$ contains more than one element}
\State Find aligned pair $\alpha=(v_{i}, v_{j})$ with same x-axis or y-axis
\If{$d(v_{i}) < d(v_{j})$}
\State Assign $v_{i}$ to $v_{j}$
\Else
\State Assign $v_{j}$ to $v_{i}$
\EndIf
\If {$v_{i}$ or $v_{j}$ is a group element}
\State Recursive update views in interface
\Else
\State Directly update views in interface
\EndIf
\State Remove $v_{i}$ and $v_{j}$ from $A$
\State Group $v_{i}$ and $v_{j}$ to a new element as $v_{g}$, and push $v_{g}$ to $A$
\EndWhile
\end{algorithmic}
\label{al:alignment}
\end{algorithm}

While aligned pair $\alpha$ is found, we need assign $\alpha$ based on direction.
For instance, the vectors in aligned pair $\alpha$ with same x-axis represents aligned direction is vertical direction.
And then elements in aligned pair $\alpha$ need to compare the other axis of elements (here, it is y-axis), denoted $d(v)$, to align.
Next, if there are group elements in aligned pair $\alpha$, we can take recursive updates. 
For example, while $v$ is consist of $v_{1}$ and $v_{2}$, we need to adjust $v_{1}$ and $v_{2}$ based on $v$ until all adjusted views are not group views.
In other conditions, the data of corresponding views in interface can be directly updated.
After updating, elements in aligned pair $\alpha$ are grouped into the new rectangle and label $g$ as group element, i.e., $(x, y, w, h, g)$.
Algorithm~\ref{al:alignment} gives the detail of the alignment process.



\begin{figure}[t]
  \centering
  % \vspace*{-1mm}
  \includegraphics[width=0.495\textwidth]{figures/fig3_stats/stats.pdf} \\{}
  % \vspace*{-4mm}
  \caption{Number of views distribution (left), and total area of view type (right).}
  \label{fig:vis_stats}
  \vspace*{-3mm}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preliminary Analysis}
\label{ssec:pre_ana}


Our annotated data enables us to preliminarily analyze statistics, i.e., the number of views distribution and the total area of each view type. The statistics of annotated data is presented in Fig.~\ref{fig:vis_stats}.

On the left, we can see the number of views distribution, where we can see most of multiple views interfaces comprise less than 5 views.
The most common layout is 3-view system.
The 4-view system is next, followed by 5-view system and 2-view system.
The result indicates most developers opt to present multiple view system by less than 6-view layout, consistent with Al-maneea and Roberts's finding ~\cite{al-maneea_2019_multipleview}. 
\yn{maybe it should be changed, since the description seems really like that in short paper }

On the right, we can see total area of each view type, where we can see majority of view types are used at above 10$\%$.
The tree and network has the largest area, followed by panel.
This may be due to the average area of tree and network is larger than the average area of panel, while the number is less than the number of panel.
And circle is basically absent from our corpus,
accounting for 3.46$\%$.
The preliminary analysis provides us with basic cognitive of multiple view design.
To fully meet the requirements in Sec.~\ref{sec:task_ana}, we develop composition and configuration analysis to explore quantitative evidences in the following section.
\yn{it is not proper to use $\%$, since it will mislead the reader that the figure is area percentage}
